{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item2Vec是一种基于Word2Vec的物品嵌入学习方法，主要用于推荐系统中学习物品的低维向量表示。\n",
    "# 核心思想是将物品看作单词，用户的交互序列看作句子，然后使用Word2Vec来学习物品之间的关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 模拟用户交互数据\n",
    "corpus = [\n",
    "    [\"iPhone\", \"MacBook\", \"AirPods\"],\n",
    "    [\"PS5\", \"Switch\", \"Xbox\"],\n",
    "    [\"MacBook\", \"iPad\", \"Magic Keyboard\"],\n",
    "    [\"iPhone\", \"iPad\", \"Apple Watch\"],\n",
    "    [\"Xbox\", \"GamePass\", \"Halo\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 创建词典\n",
    "word2idx = {}\n",
    "idx2word = {}\n",
    "idx = 0\n",
    "for sentence in corpus:\n",
    "    for word in sentence:\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = idx\n",
    "            idx2word[idx] = word\n",
    "            idx += 1\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "window_size = 1  # 只考虑相邻的物品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 1,  0],\n",
       "        [ 1,  2],\n",
       "        [ 2,  1],\n",
       "        [ 3,  4],\n",
       "        [ 4,  3],\n",
       "        [ 4,  5],\n",
       "        [ 5,  4],\n",
       "        [ 1,  6],\n",
       "        [ 6,  1],\n",
       "        [ 6,  7],\n",
       "        [ 7,  6],\n",
       "        [ 0,  6],\n",
       "        [ 6,  0],\n",
       "        [ 6,  8],\n",
       "        [ 8,  6],\n",
       "        [ 5,  9],\n",
       "        [ 9,  5],\n",
       "        [ 9, 10],\n",
       "        [10,  9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 生成 Skip-gram 训练数据\n",
    "training_data = []\n",
    "for sentence in corpus:\n",
    "    indices = [word2idx[word] for word in sentence]\n",
    "    for center_idx, center_word in enumerate(indices):\n",
    "        for offset in range(-window_size, window_size + 1):\n",
    "            context_idx = center_idx + offset\n",
    "            if offset == 0 or context_idx < 0 or context_idx >= len(indices):\n",
    "                continue\n",
    "            training_data.append((center_word, indices[context_idx])) # (center, context)\n",
    "\n",
    "training_data = torch.tensor(training_data)\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 定义 Item2Vec (Skip-gram) 模型\n",
    "class Item2Vec(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Item2Vec, self).__init__()\n",
    "        self.WI = nn.Embedding(vocab_size, embedding_dim)  # 中心词向量空间 (V x N)\n",
    "        self.WO = nn.Embedding(vocab_size, embedding_dim)  # 上下文词向量空间 (V x N)\n",
    "\n",
    "    def forward(self, center_idx):\n",
    "        v_c = self.WI(center_idx)  # (batch_size, embedding_dim)\n",
    "        scores = torch.matmul(v_c, self.WO.weight.T)  # (batch_size, vocab_size)\n",
    "        return scores\n",
    "\n",
    "embedding_dim = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Item2Vec(vocab_size, embedding_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 101.7523\n",
      "Epoch 10, Loss: 21.5140\n",
      "Epoch 20, Loss: 16.8474\n",
      "Epoch 30, Loss: 16.1054\n",
      "Epoch 40, Loss: 15.8451\n",
      "Epoch 50, Loss: 15.7187\n",
      "Epoch 60, Loss: 15.6448\n",
      "Epoch 70, Loss: 15.5957\n",
      "Epoch 80, Loss: 15.5602\n",
      "Epoch 90, Loss: 15.5326\n",
      "\n",
      "Learned word vectors:\n",
      "iPhone: [ 0.10257793  2.2753115   1.089999    1.1591762   0.78177196 -0.73553616\n",
      "  0.02159385 -0.02105704 -0.20757978  1.1321979 ]\n",
      "MacBook: [ 1.0998651  -0.428761   -0.7472727  -0.02003135  1.7789153   0.68190455\n",
      "  1.84901    -0.5654099  -0.37160477 -0.14102161]\n",
      "AirPods: [-1.392579    0.07051965  1.8836502   1.2164317   0.73689806  0.5570067\n",
      "  0.13493632 -2.1850996  -1.3617554   0.5889098 ]\n",
      "PS5: [-0.1674017   1.8469607   2.5034945  -2.3784306  -0.8938814   0.19561696\n",
      "  0.5336491   2.4609773  -0.68164474 -0.14437471]\n",
      "Switch: [-0.15312459  1.8753009  -0.57060003 -1.8458759  -1.3570073   0.30829924\n",
      " -1.2800428  -1.4402593   0.29729474 -0.29711217]\n",
      "Xbox: [ 1.5762222   2.3378627   0.2958379  -0.59735054  1.2043834   0.01723105\n",
      " -0.43876225  1.3460426  -1.3633534  -1.1710902 ]\n",
      "iPad: [-1.2015654   0.38221842 -1.4604906   1.1726214   1.2517464  -0.8295168\n",
      "  1.1483635  -0.92288244  0.38894215 -0.3777981 ]\n",
      "Magic Keyboard: [ 1.6441774  -1.2814817   1.2251247   0.6816348   1.0343482   0.16260864\n",
      " -0.61692744  0.7083895   0.17753853  1.0375496 ]\n",
      "Apple Watch: [ 1.8907933  -0.37788042 -0.06575474  1.9071064   0.41233408 -0.9280602\n",
      "  0.83395875  1.5894868   1.5081567   0.10961792]\n",
      "GamePass: [-0.4098261  -0.60731465  0.00510109  1.3827178  -3.2126517   1.9494371\n",
      " -1.1132648   0.48135296 -1.7268815   0.25534073]\n",
      "Halo: [ 0.73400253 -0.8645473  -1.8106198   0.00284823 -0.87803584 -2.1035862\n",
      " -1.7973511   2.5936043   1.3113588   0.89358085]\n"
     ]
    }
   ],
   "source": [
    "# 5. 训练模型\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for center, context in training_data:\n",
    "        center, context = center.to(device), context.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(center.unsqueeze(0))  # 增加 batch 维度\n",
    "        loss = criterion(scores, context.unsqueeze(0))  # 计算损失\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# 打印训练后的词向量\n",
    "print(\"\\nLearned word vectors:\")\n",
    "for word, idx in word2idx.items():\n",
    "    print(f\"{word}: {model.WI.weight[idx].detach().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items similar to 'iPhone':\n",
      "  Xbox: 0.3999\n",
      "  AirPods: 0.3779\n",
      "  PS5: 0.2122\n",
      "  Apple Watch: 0.1910\n",
      "  iPad: 0.1637\n",
      "\n",
      "Items similar to 'PS5':\n",
      "  Xbox: 0.5001\n",
      "  iPhone: 0.2122\n",
      "  Switch: 0.1921\n",
      "  GamePass: 0.0297\n",
      "  Magic Keyboard: -0.0643\n",
      "\n",
      "Items similar to 'MacBook':\n",
      "  iPad: 0.3937\n",
      "  Apple Watch: 0.2109\n",
      "  Magic Keyboard: 0.1723\n",
      "  Xbox: 0.1485\n",
      "  AirPods: 0.0510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_similar_items(item, top_k=5):\n",
    "    if item not in word2idx:\n",
    "        return f\"Item '{item}' not found in the vocabulary.\"\n",
    "    \n",
    "    item_idx = word2idx[item]\n",
    "    item_vector = model.WI.weight[item_idx].detach().numpy().reshape(1, -1)\n",
    "    \n",
    "    similarities = {}\n",
    "    for other_item, other_idx in word2idx.items():\n",
    "        if other_item == item:\n",
    "            continue\n",
    "        other_vector = model.WI.weight[other_idx].detach().numpy().reshape(1, -1)\n",
    "        similarity = cosine_similarity(item_vector, other_vector)[0][0]\n",
    "        similarities[other_item] = similarity\n",
    "    \n",
    "    similar_items = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    return similar_items\n",
    "\n",
    "# 测试一些物品\n",
    "test_items = [\"iPhone\", \"PS5\", \"MacBook\"]\n",
    "for item in test_items:\n",
    "    print(f\"Items similar to '{item}':\")\n",
    "    similar_items = get_similar_items(item)\n",
    "    for similar_item, similarity in similar_items:\n",
    "        print(f\"  {similar_item}: {similarity:.4f}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
